{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import pickle, gzip, os, time, shutil, torch, matplotlib as mpl, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import tensor, nn \n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_close\n",
    "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
    "np.set_printoptions(precision=2, linewidth=125)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "path_data = Path('data')\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f:\n",
    "    ((x_train, y_train),(x_valid, y_valid), _) = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train, x_valid, y_valid))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initail setup\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, 10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp() / (x.exp().sum(-1, keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.39, -2.24, -2.12,  ..., -2.27, -2.22, -2.53],\n",
       "        [-2.41, -2.11, -2.21,  ..., -2.29, -2.34, -2.45],\n",
       "        [-2.35, -2.34, -2.13,  ..., -2.22, -2.19, -2.48],\n",
       "        ...,\n",
       "        [-2.26, -2.25, -2.11,  ..., -2.32, -2.23, -2.45],\n",
       "        [-2.33, -2.30, -2.11,  ..., -2.29, -2.31, -2.39],\n",
       "        [-2.35, -2.36, -2.13,  ..., -2.22, -2.23, -2.46]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x-m[:,None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred = log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.39, -2.24, -2.12,  ..., -2.27, -2.22, -2.53],\n",
       "        [-2.41, -2.11, -2.21,  ..., -2.29, -2.34, -2.45],\n",
       "        [-2.35, -2.34, -2.13,  ..., -2.22, -2.19, -2.48],\n",
       "        ...,\n",
       "        [-2.26, -2.25, -2.11,  ..., -2.32, -2.23, -2.45],\n",
       "        [-2.33, -2.30, -2.11,  ..., -2.29, -2.31, -2.39],\n",
       "        [-2.35, -2.36, -2.13,  ..., -2.22, -2.23, -2.46]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "def accuracy(out, yb):\n",
    "    return (out.argmax(dim=1) == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "def report(loss, preds, yb):\n",
    "    print(f'{loss:.2f}, {accuracy(preds, yb):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (act): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Module()\n",
    "#\n",
    "# \n",
    "m.foo = nn.Linear(3,4)\n",
    "m.act = nn.ReLU()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True)), ('act', ReLU())]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = nn.ModuleList([nn.Linear(3,4), nn.ReLU()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (1): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.23, -0.32, -0.45],\n",
       "         [ 0.23, -0.49, -0.41],\n",
       "         [ 0.05, -0.01, -0.32],\n",
       "         [-0.36,  0.10,  0.24]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.21, -0.51, -0.12, -0.56], requires_grad=True)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ml.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children():\n",
    "    print(f'{name}: {l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.98\n",
      "0.04, 1.00\n",
      "0.03, 1.00\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "bs = 50\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return model, optim.SGD(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = slice(0,50)\n",
    "model , opt = get_model()\n",
    "loss = loss_func(model(x_train[s]), y_train[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.29, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "class Dataset():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, idx): return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "assert len(train_ds) == len(x_train)\n",
    "assert len(valid_ds) == len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs):\n",
    "        self.ds = ds \n",
    "        self.bs = bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds),self.bs): yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    model, opt = get_model()\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19, 0.94\n",
      "0.13, 0.92\n",
      "0.16, 0.92\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, shuffle=False):\n",
    "        self.n = len(ds)\n",
    "        self.shuffle = shuffle\n",
    "    def __iter__(self):\n",
    "        res = list(range(self.n))\n",
    "        if self.shuffle: random.shuffle(res)\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Sampler(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "it = iter(ss)\n",
    "for o in range(5):\n",
    "    print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(ss,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Sampler(train_ds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3309, 1193, 24811, 38587, 25344]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(ss,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler():\n",
    "    def __init__(self, sampler, bs, drop_last=False): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12949, 37021, 40078, 37986, 25820, 48690, 44851],\n",
       " [9750, 38898, 38808, 1045, 41209, 27777, 25765],\n",
       " [25248, 29588, 48195, 30441, 44165, 31737, 36551],\n",
       " [16452, 41770, 31735, 30775, 25824, 18769, 40575],\n",
       " [25029, 24493, 3407, 15891, 29667, 16460, 22317],\n",
       " [28064, 28296, 21686, 34090, 14059, 35923, 44003],\n",
       " [16631, 1011, 9737, 39814, 11033, 24289, 24917],\n",
       " [7316, 38127, 38694, 24529, 8669, 17297, 13558],\n",
       " [34112, 31585, 4748, 6575, 14313, 8708, 27719],\n",
       " [33869, 35194, 41, 8652, 8994, 23981, 12708]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = BatchSampler(ss,7)\n",
    "list(islice(batches, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batches, collate_fn= collate): fc.store_attr()\n",
    "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,batches=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batches=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd8dc742320>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiiprocessing in dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp \n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[3,6,8, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__([3,6,8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "for o in map(train_ds.__getitem__,([3,6],[8,1])): print (o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batches, n_workers=1, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        with mp.Pool(self.n_workers) as ex:\n",
    "            yield from ex.map(self.ds.__getitem__, iter(self.batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "from torch.utils.data import DataLoader, SequentialSampler, BatchSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(RandomSampler(train_ds), bs, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41, 0.90\n",
      "0.01, 1.00\n",
      "0.03, 1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> pytorch can auto generate the batch sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or this can be done using the shuffle \n",
    "train_dl = DataLoader(train_ds, bs, shuffle=True, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs,shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09, 0.94\n",
      "0.07, 0.96\n",
      "0.03, 1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc, count = 0.,0., 0\n",
    "            for xb, yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                n = len(xb)\n",
    "                count +=n\n",
    "                tot_loss += loss_func(pred, yb).item() * n\n",
    "                tot_acc += accuracy(pred, yb).item() * n\n",
    "        print(epoch, tot_loss/ count, tot_acc/count)\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "def get_dls(train_ds, valid_ds, bs, **kwarg):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwarg),\n",
    "            DataLoader(valid_ds, batch_size=bs, shuffle=False, **kwarg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.15082009656820447 0.9536999994516373\n",
      "1 0.13534947886597365 0.9602999997138977\n",
      "2 0.11357427586830454 0.9674000003933907\n",
      "3 0.10747459832200548 0.9704000002145767\n",
      "4 0.10799022649851395 0.9704999986290932\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "loss, acc = fit(5, model=model, loss_func=loss_func, opt=opt, train_dl=train_dl, valid_dl=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/DL/lib/python3.10/site-packages/nbdev/export.py:54: UserWarning: Notebook '/Volumes/Others/Fastai course/miniai/nbs/05_datasets.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n"
     ]
    }
   ],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
